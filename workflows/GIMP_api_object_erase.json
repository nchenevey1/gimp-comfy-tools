{
  "3": {
    "inputs": {
      "ckpt_name": "1.5_photon_v1.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "6": {
    "inputs": {
      "seed": 1119739014071437,
      "steps": 15,
      "cfg": 5,
      "sampler_name": "ddim",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "76",
        0
      ],
      "positive": [
        "35",
        0
      ],
      "negative": [
        "77",
        0
      ],
      "latent_image": [
        "8",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "8": {
    "inputs": {
      "grow_mask_by": 0,
      "pixels": [
        "30",
        0
      ],
      "vae": [
        "3",
        2
      ],
      "mask": [
        "33",
        0
      ]
    },
    "class_type": "VAEEncodeForInpaint",
    "_meta": {
      "title": "VAE Encode (for Inpainting)"
    }
  },
  "9": {
    "inputs": {
      "samples": [
        "6",
        0
      ],
      "vae": [
        "3",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "10": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "56",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "13": {
    "inputs": {
      "upscale_method": "bilinear",
      "scale_by": 0.5,
      "image": [
        "49",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "Upscale Image By"
    }
  },
  "19": {
    "inputs": {
      "seed": 438304511733081,
      "steps": 20,
      "cfg": 5,
      "sampler_name": "dpmpp_2m_sde_gpu",
      "scheduler": "normal",
      "denoise": 0.4,
      "model": [
        "76",
        0
      ],
      "positive": [
        "82",
        0
      ],
      "negative": [
        "77",
        0
      ],
      "latent_image": [
        "26",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "21": {
    "inputs": {
      "samples": [
        "19",
        0
      ],
      "vae": [
        "3",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "26": {
    "inputs": {
      "pixels": [
        "55",
        0
      ],
      "vae": [
        "3",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "30": {
    "inputs": {
      "upscale_method": "bilinear",
      "scale_by": 0.5,
      "image": [
        "85",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "Upscale Image By"
    }
  },
  "31": {
    "inputs": {
      "upscale_method": "bilinear",
      "scale_by": 0.5,
      "image": [
        "80",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "Upscale Image By"
    }
  },
  "33": {
    "inputs": {
      "channel": "red",
      "image": [
        "31",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "Convert Image to Mask"
    }
  },
  "34": {
    "inputs": {
      "black_pixel_for_xinsir_cn": false,
      "image": [
        "85",
        0
      ],
      "mask": [
        "33",
        0
      ]
    },
    "class_type": "InpaintPreprocessor",
    "_meta": {
      "title": "Inpaint Preprocessor"
    }
  },
  "35": {
    "inputs": {
      "strength": 1,
      "conditioning": [
        "82",
        0
      ],
      "control_net": [
        "37",
        0
      ],
      "image": [
        "34",
        0
      ]
    },
    "class_type": "ControlNetApply",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "37": {
    "inputs": {
      "control_net_name": "control_v11p_sd15_inpaint.pth"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "49": {
    "inputs": {
      "upscale_model": [
        "50",
        0
      ],
      "image": [
        "9",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "50": {
    "inputs": {
      "model_name": "4xNMKDSuperscale_4xNMKDSuperscale.pt"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "52": {
    "inputs": {
      "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "55": {
    "inputs": {
      "force_resize_width": 0,
      "force_resize_height": 0,
      "image": [
        "13",
        0
      ],
      "mask": [
        "59",
        0
      ]
    },
    "class_type": "Cut By Mask",
    "_meta": {
      "title": "Cut By Mask"
    }
  },
  "56": {
    "inputs": {
      "resize_behavior": "resize",
      "image_base": [
        "85",
        0
      ],
      "image_to_paste": [
        "61",
        0
      ],
      "mask": [
        "59",
        0
      ]
    },
    "class_type": "Paste By Mask",
    "_meta": {
      "title": "Paste By Mask"
    }
  },
  "58": {
    "inputs": {
      "images": [
        "55",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "59": {
    "inputs": {
      "padding": 32,
      "constraints": "multiple_of",
      "constraint_x": 64,
      "constraint_y": 64,
      "min_width": 512,
      "min_height": 512,
      "batch_behavior": "match_ratio",
      "mask": [
        "80",
        0
      ]
    },
    "class_type": "Mask To Region",
    "_meta": {
      "title": "Mask To Region"
    }
  },
  "61": {
    "inputs": {
      "op": "multiply_alpha",
      "clamp_result": "yes",
      "round_result": "no",
      "image1": [
        "21",
        0
      ],
      "image2": [
        "69",
        0
      ]
    },
    "class_type": "Combine Masks",
    "_meta": {
      "title": "Combine Masks"
    }
  },
  "62": {
    "inputs": {
      "force_resize_width": 0,
      "force_resize_height": 0,
      "image": [
        "80",
        0
      ],
      "mask": [
        "59",
        0
      ]
    },
    "class_type": "Cut By Mask",
    "_meta": {
      "title": "Cut By Mask"
    }
  },
  "68": {
    "inputs": {
      "method": "intensity",
      "image": [
        "62",
        0
      ]
    },
    "class_type": "Image To Mask",
    "_meta": {
      "title": "Image To Mask"
    }
  },
  "69": {
    "inputs": {
      "mask": [
        "68",
        0
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "74": {
    "inputs": {
      "ipadapter_file": "ip-adapter_sd15.safetensors"
    },
    "class_type": "IPAdapterModelLoader",
    "_meta": {
      "title": "IPAdapter Model Loader"
    }
  },
  "76": {
    "inputs": {
      "weight": 1,
      "weight_type": "linear",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "model": [
        "3",
        0
      ],
      "ipadapter": [
        "74",
        0
      ],
      "image": [
        "85",
        0
      ],
      "attn_mask": [
        "78",
        0
      ],
      "clip_vision": [
        "52",
        0
      ]
    },
    "class_type": "IPAdapterAdvanced",
    "_meta": {
      "title": "IPAdapter Advanced"
    }
  },
  "77": {
    "inputs": {
      "text": "people, person, man, woman, boy, girl, error, blurry, distorted, low res",
      "clip": [
        "3",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt) Negative"
    }
  },
  "78": {
    "inputs": {
      "red": 255,
      "green": 255,
      "blue": 255,
      "threshold": 0,
      "image": [
        "80",
        0
      ]
    },
    "class_type": "MaskFromColor+",
    "_meta": {
      "title": "ðŸ”§ Mask From Color"
    }
  },
  "80": {
    "inputs": {
      "radius": 10,
      "sigma_factor": 1,
      "image": [
        "84",
        0
      ]
    },
    "class_type": "Blur",
    "_meta": {
      "title": "Blur"
    }
  },
  "82": {
    "inputs": {
      "text": "beach, ocean, water, sand, outdoors, best quality, high res",
      "clip": [
        "3",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt) Positive"
    }
  },
  "83": {
    "inputs": {
      "mask": "",
      "width": 512,
      "height": 512
    },
    "class_type": "NC_LoadMaskGIMP",
    "_meta": {
      "title": "Load Mask (GIMP)"
    }
  },
  "84": {
    "inputs": {
      "mask": [
        "83",
        0
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "85": {
    "inputs": {
      "image": "",
      "width": 512,
      "height": 512
    },
    "class_type": "NC_LoadImageGIMP",
    "_meta": {
      "title": "Load Image (GIMP)"
    }
  },
  "86": {
    "inputs": {
      "images": [
        "56",
        0
      ]
    },
    "class_type": "NC_SendImageDimsWebSocketGIMP",
    "_meta": {
      "title": "Send Image with Dimensions GIMP (WebSocket)"
    }
  }
}